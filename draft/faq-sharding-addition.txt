What are the best ways to successfully insert larger volumes of data into as sharded collection? 
------------------------------------------------------------------------------------------------

- what is pre-splitting 

  In sharded environments, MongoDB distributes data into :term:`chunks
  <chunk>`, each defined by a range of shard key values. Pre-splitting is a command run
  prior to data insertion that specifies the shard key values on which to split up chunks.

- Pre-splitting is useful before large inserts into a sharded collection when: 

1. inserting data into an empty collection

If a collection is empty, the database takes time to determine the optimal key
distribution. If you insert many documents in rapid succession, MongoDB will initially
direct writes to a single chunk, potentially having significant impacts on performance.
Predefining splits may improve write performance in the early stages of a bulk import by
eliminating the database's "learning" period.

2. data is not evenly distributed 

Even if the sharded collection was previously populated with documents and contains multiple
chunks, pre-splitting may be beneficial if the write operation isn't evenly distributed, in
other words, if the inserts have shard keys values contained on a small number of chunks.

3. monotomically increasing shard key

If you attempt to insert data with monotonically increasing shard keys, the writes will
always hit the last chunk in the collection. Predefining splits may help to cycle a large
write operation around the cluster; however, pre-splitting in this instance will not
prevent consecutive inserts from hitting a single shard.

- when does it not matter

If data insertion is not rapid, MongoDB may have enough time to split and migrate chunks without
impacts on performance. In addition, if the collection already has chunks with an even key
distribution, pre-splitting may not be necessary. 

See the ":doc:`/tutorial/inserting-documents-into-a-sharded-collection`" tutorial for more
information.


Is it necessary to pre-split data before high volume inserts into a sharded collection?
---------------------------------------------------------------------------------------

The answer depends on the shard key, the existing distribution of chunks, and how
evenly distributed the insert operation is. If a collection is empty prior to a
bulk insert, the database will take time to determine the optimal key
distribution. Predefining splits improves write performance in the early stages
of a bulk import.

Pre-splitting is also important if the write operation isn't evenly distributed.
When using an increasing shard key, for example, pre-splitting data can prevent
writes from hammering a single shard.
