=================================
Backup and Restoration Strategies
=================================

.. default-domain:: mongodb

This document provides an inventory of database backup strategies for
use with MongoDB. This document contains the following sections:

- :ref:`backup-overview` and :ref:`backup-considerations` describe the
  approaches for backing up your MongoDB environment.

- :ref:`block-level-backup` and :ref:`database-dumps` describe specific
  strategies.

- :ref:`backups-with-sharding-and-replication` describes considerations
  specific to :term:`replica sets <replica set>` and :term:`sharded
  clusters <sharded cluster>`.

.. _backup-overview:

Backup Overview
---------------

Production systems should always have some consideration and strategy
for taking and restoring backups. The goal of a backup strategy is to
produce a full and consistent copy of the data that you can use to
bring up a new or replacement database instance. However, in some
cases, taking backups is difficult or impossible, given large data
volumes, distributed architectures, and data transmission speeds.

Nevertheless, with MongoDB, there are two major approaches to backups:
[#replication-as-backups]_

- Using system-level tools, like disk image snapshots.

  See :ref:`block-level-backup`.

- Using various capacities present in the :program:`mongodump` tool.

  See :ref:`database-dumps`.

The methods described in this document operate by copying the data file
on the disk level. If your system does not provide functionality for
this kind of backup, see the section on :ref:`database-dumps`.

Ensuring that the state captured by the backup is consistent and usable
is the primary challenge of producing backups of database systems.
Backups that you cannot produce reliably, or restore from feasibly are
worthless.

As you develop your backup system, take into consideration the specific
features of your deployment, your use patterns, and your architecture.

Because every environment is unique it's important to regularly test the
backups that you capture to ensure that your backup system is
practically, and not just theoretically, functional.

.. [#replication-as-backups] In many situations increasing the amount
   of replication provides useful assurances with data sets that are
   difficult to restore in a timely manner.

.. _backup-considerations:

Production Considerations for Backup Strategies
-----------------------------------------------

When evaluating a backup strategy for your MongoDB deployment consider
the following factors:

- Geography. Ensure that you move some backups away from the your
  primary database infrastructure. It's important to be able to
  restore your database if you lose access to a system or site.

- System errors. Ensure that your backups can survive situations where
  hardware failures or disk errors impact the integrity or
  availability of your backups.

- Production constraints. Backup operations themselves sometimes
  require substantial system resources. It's important to consider the
  time of the backup schedule relative to peak usage and maintenance
  windows.

- System capabilities. Some of the block-level
  snapshot tools requires special support on the operating-system or
  infrastructure level.

- Database configuration. :term:`Replication` and :term:`sharding
  <shard>` can affect the process, and impact of the backup implementation.

- Actual requirements. You may be able to save time, effort, and space
  by including only crucial data in the most frequent backups and
  backing up less crucial data less frequently.

With this information in hand you can begin to develop a backup plan
for your database. Remember that all backup plans must be:

- Tested. If you cannot effectively restore your database from the
  backup, then your backups are useless. Test backup restoration
  regularly in practical situations to ensure that your backup system
  provides value.

- Automated. Database backups need to run regularly and
  automatically. Also automate tests of backup restoration.

.. _database-dumps:

Using Binary Database Dumps for Backups
---------------------------------------

This section describes the process for writing the entire contents of
your MongoDB instance to a file in a binary format. If
disk-level snapshots are not available, this approach
provides the best option for full system database backups.

.. seealso::

   The :doc:`/reference/mongodump` and :doc:`/reference/mongorestore`
   documents contain complete documentation of these tools. If you
   have questions about these tools not covered here, please refer to
   these documents.

   If your system has disk level snapshot capabilities, consider the
   backup methods described in :ref:`block-level-backup`.

Database Dump with ``mongodump``
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The :program:`mongodump` utility can perform a live backup of data or
can work against an inactive set of database files.
The :program:`mongodump` utility can create a dump for an entire
server/database/collection (or part of a collection using of query),
even when the database is running and active. If you run
:program:`mongodump` without any arguments, the command connects to
the local database instance (e.g. ``127.0.0.1`` or ``localhost``) and
creates a database backup named ``dump/`` in the current directory.

.. include:: /includes/note-mongodump-compatibility-2.2.rst

To limit the amount of data included in the database dump, you can
specify :option:`--database <mongodump --database>` and
:option:`--collection <mongodump --collection>` as options to the
:program:`mongodump` command. For example:

.. code-block:: sh

   mongodump --collection collection --db test

This command creates a dump of the collection named ``collection``
from the database ``test`` in a :file:`dump/` subdirectory of the current
working directory.

Use the :option:`--oplog <mongodump --oplog>` option with
:program:`mongodump` to collect the :term:`oplog` entries to build a
point-in-time snapshot of a database within a replica set. With :option:`--oplog
<mongodump --oplog>`, :program:`mongodump` copies all the data from
the source database as well as all of the :term:`oplog` entries from
the beginning of the backup procedure to until the backup procedure
completes. This backup procedure, in conjunction with
:option:`mongorestore --oplogReplay <mongorestore --oplogReplay>`,
allows you to restore a backup that reflects a consistent and specific
moment in time.

If your MongoDB instance is not running, you can use the
:option:`--dbpath <mongodump --dbpath>` option to specify the
location to your MongoDB instance's database files. :program:`mongodump`
reads from the data files directly with this operation. This
locks the data directory to prevent conflicting writes. The
:program:`mongod` process must *not* be running or attached to these
data files when you run :program:`mongodump` in this
configuration. Consider the following example:

.. code-block:: sh

   mongodump --dbpath /srv/mongodb

Additionally, the :option:`--host <mongodump --host>` and
:option:`--port <mongodump --port>` options allow you to specify a
non-local host to connect to capture the dump. Consider the following
example:

.. code-block:: sh

   mongodump --host mongodb1.example.net --port 3017 --username user --password pass --out /opt/backup/mongodump-2011-10-24

On any :program:`mongodump` command you may, as above, specify username
and password credentials to specify database authentication.

.. _backup-restore-dump:

Restore Database from Binary Dump with ``mongorestore``
```````````````````````````````````````````````````````

The :program:`mongorestore` utility restores a binary backup created by
:program:`mongodump`. Consider the following example command:

.. code-block:: sh

   mongorestore dump-2011-10-25/

Here, :program:`mongorestore` imports the database backup located in
the :file:`dump-2011-10-25` directory to the :program:`mongod` instance
running on the localhost interface. By default, :program:`mongorestore`
looks for a database dump in the :file:`dump/` directory and restores
that. If you wish to restore to a non-default host, the
:option:`--host <mongorestore --host>` and :option:`--port <mongorestore --port>`
options allow you to specify a non-local host to connect to capture
the dump. Consider the following example:

.. code-block:: sh

   mongorestore --host mongodb1.example.net --port 3017 --username user --password pass /opt/backup/mongodump-2011-10-24

On any :program:`mongorestore` command you may specify
username and password credentials, as above.

If you created your database dump using the :option:`--oplog
<mongodump --oplog>` option to ensure a point-in-time snapshot, call
:program:`mongorestore` with the
:option:`--oplogReplay <mongorestore --oplogReplay>`
option, as in the following example:

.. code-block:: sh

   mongorestore --oplogReplay

You may also consider using the :option:`mongorestore --objcheck`
option to check the integrity of objects while inserting them into the
database, or you may consider the :option:`mongorestore --drop` option to drop each
collection from the database before restoring from
backups. :program:`mongorestore` also includes the ability to a filter
to all input before inserting it into the new database. Consider the
following example:

.. code-block:: sh

   mongorestore --filter '{"field": 1}'

Here, :program:`mongorestore` only adds documents to the database from
the dump located in the :file:`dump/` folder *if* the documents have a
field name ``field`` that holds a value of ``1``. Enclose the
filter in single quotes (e.g. ``'``) to prevent the filter from
interacting with your shell environment.

.. code-block:: sh

   mongorestore --dbpath /srv/mongodb --journal

Here, :program:`mongorestore` restores the database dump located in
:file:`dump/` folder into the data files located at :file:`/srv/mongodb`.
Additionally,
the :option:`--journal <mongorestore --journal>` option ensures that
:program:`mongorestore` records all operation in the durability
:term:`journal`. The journal prevents data file corruption if anything
(e.g. power failure, disk failure, etc.)  interrupts the restore
operation.

.. seealso:: :doc:`/reference/mongodump` and
   :doc:`/reference/mongorestore`.

.. _backups-with-sharding-and-replication:

Sharded Cluster and Replica Set Backups
---------------------------------------

The underlying architecture of :term:`sharded clusters <sharded
cluster>` and :term:`replica sets <replica set>` presents several
challenges for creating backups. This section describes how to make
quality backups in environments with these configurations and how to
perform restorations.

.. _sharded-cluster-backups:

Sharded Cluster Backup Considerations
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. include:: /includes/note-shard-cluster-backup.rst

Sharded clusters complicate backup operations, as distributed
systems. True point-in-time backups are only possible when stopping all write
activity from the application. To create a precise moment-in-time
snapshot of a cluster, stop all application write activity to the
database, capture a backup, and only allow write operations to the
database after the backup is complete.

However, you can capture a backup of a cluster that **approximates** a
point-in-time backup by capturing a backup from a secondary member of
the replica sets that provide the shards in the cluster at roughly the
same moment. If you decide to use an approximate-point-in-time backup
method, ensure that your application can operate using a copy of the
data that does not reflect a single moment in time.

The following documents describe all sharded cluster related backup
procedures:

- :doc:`/tutorial/backup-small-sharded-cluster-with-mongodump`
- :doc:`/tutorial/backup-sharded-cluster-with-filesystem-snapshots`
- :doc:`/tutorial/backup-sharded-cluster-with-database-dumps`
- :doc:`/tutorial/schedule-backup-window-for-sharded-clusters`
- :doc:`/tutorial/restore-single-shard`
- :doc:`/tutorial/restore-sharded-cluster`

.. _replica-set-backups:

Replica Set Backup Considerations
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In most cases, backing up data stored in a :term:`replica set` is
similar to backing up data stored in a single instance. It's possible to
lock a single :term:`secondary` or :term:`slave` database and then
on create a backup from that instance. When you unlock the database, the secondary or
slave  will catch up with the :term:`primary` or :term:`master`. You may also
chose to deploy a dedicated :term:`hidden member` for backup purposes.

If you have a :term:`sharded cluster` where each :term:`shard` is itself a replica
set, you can use this method to create a backup of the entire cluster
without disrupting the operation of the node. In these situations you
should still turn off the balancer when you create backups.

For any cluster, using a non-primary/non-master node to create backups is
particularly advantageous in that the backup operation does not
affect the performance of the primary or master. Replication
itself provides some measure of redundancy. Nevertheless, keeping
point-in time backups of your cluster to provide for disaster recovery
and as an additional layer of protection is crucial.
