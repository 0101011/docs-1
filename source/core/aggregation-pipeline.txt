====================
Aggregation Pipeline
====================

.. versionadded:: 2.1

.. default-domain:: mongodb

The aggregation pipeline is a framework for performing aggregation
tasks, modeled on the concept of data processing pipelines. Using this
framework, MongoDB passes the documents of a single :term:`collection`
through a :ref:`pipeline <aggregation-pipeline>`. The pipeline
transforms the documents into aggregated results.

The aggregation pipeline provides an alternative to :term:`map-reduce`
and may be the preferred solution for many aggregation tasks where the
complexity of map-reduce may be unwarranted.

.. _aggregation-pipeline:

Pipeline
--------

Conceptually, documents from a collection pass through an aggregation
pipeline, which transforms these objects as they pass through. For
those familiar with UNIX-like shells (e.g. bash,) the concept is
analogous to the pipe (i.e. ``|``). In a shell environment, the pipe
redirects a stream of characters from the output of one process to the
input of the next. 

The MongoDB aggregation pipeline starts with the documents of a
collection and streams the documents from one :ref:`pipeline operator
<aggregation-pipeline-operator-reference>` to the next to process the
documents. Each operator in the pipeline transforms each document as it
passes through the pipeline. Pipeline operators do not need to produce
one output document for every input document. Operators may generate
new documents or filter out documents. Pipeline operators can be
repeated in the pipe.

.. include:: /includes/warning-aggregation-types.rst

.. seealso:: :ref:`aggregation-pipeline-operator-reference`

.. _aggregation-expressions:

Pipeline Expressions
--------------------

Pipeline operator expressions provide the specifications for the
transformation to the input documents. The aggregation pipeline defines
expressions using a document structure. The expressions can contain
fields, values, and :ref:`operators
<aggregation-expression-operators>`. In an expression, to access the
fields that existed in the input collection, prefix the field name with
``$`` and enclose in quotes. To access new fields created in the
pipeline, use the field name without modification.

Pipeline expressions can only operate on the current document in the
pipeline and cannot refer to data from other documents.

Generally, expressions are stateless and are only evaluated when seen
by the aggregation process with one exception: :term:`accumulator`
expressions. The accumulator expressions, used with the
:pipeline:`$group` pipeline operator, maintain their state (e.g.
totals, maximums, minimums, and related data) as documents progress
through the pipeline.

For the expression operators, see
:ref:`aggregation-expression-operators`.

``aggregate`` Command
---------------------

To use the aggregation pipeline, MongoDB interfaces provide the
:dbcommand:`aggregate` command. In the :program:`mongo` shell, MongoDB
provides the :method:`db.collection.aggregate()` wrapper. The command
and the corresponding :program:`mongo` shell wrapper accept as
arguments a sequence of :ref:`pipeline operations
<aggregation-pipeline-operator-reference>`. The result of the operation
is a document and is subject to the :ref:`BSON Document size
<limit-bson-document-size>` limit, which is currently 16 megabytes.

For usage examples, see
:doc:`/tutorial/aggregation-with-user-preference-data` and
:doc:`/tutorial/aggregation-zip-code-data-set` as well as the
:dbcommand:`aggregate` command and the
:method:`db.collection.aggregate()` method reference pages.

See :doc:`/core/aggregation-pipeline-limits` for details on limits and
restrictions on the aggregation pipeline.

.. _aggregation-optimize-performance:

Aggregation Pipeline Behavior
-----------------------------

In MongoDB, the :dbcommand:`aggregate` operate on a single collection,
logically passing the *entire* collection into the aggregation
pipeline. Whenever possible, avoid scanning the entire collection to
optimize the operation.

Early Filtering
~~~~~~~~~~~~~~~

If your aggregation operation requires only a subset of the data in a
collection, use the :pipeline:`$match` operator to restrict which items go
in to the top of the pipeline, as in a query. When placed early in a
pipeline, these :pipeline:`$match` operations use suitable indexes
to scan only the matching documents in a collection.

Placing a :pipeline:`$match` pipeline stage followed by a
:pipeline:`$sort` stage at the start of the pipeline is logically
equivalent to a single query with a sort and can use an index. When
possible, place :pipeline:`$match` operators at the beginning of the
pipeline.

.. _aggregation-pipeline-operators-and-performance:

Pipeline Operators and Indexes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The :pipeline:`$match`, :pipeline:`$sort`, :pipeline:`$limit`, and
:pipeline:`$skip` pipeline operators can take advantage of an index
when they occur at the **beginning** of the pipeline or when they
occur **before** the following aggregation operators:
:pipeline:`$project`, :pipeline:`$unwind`, and :pipeline:`$group`.

.. versionadded:: 2.4
   The :pipeline:`$geoNear` pipeline operator takes advantage of a
   geospatial index. When using :pipeline:`$geoNear`, the
   :pipeline:`$geoNear` pipeline operation must appear as the first
   stage in an aggregation pipeline.

Additional Features
~~~~~~~~~~~~~~~~~~~

The aggregation pipeline has an internal optimization phase that
provides improved performance for certain sequence of operators. For
details, see :ref:`aggregation-pipeline-sequence-optimization`.

The aggregation pipeline supports operations on sharded collections.
See :ref:`aggregation-pipeline-sharded-collection`.
