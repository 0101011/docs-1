============================================
Operational Considerations for Data Modeling
============================================

.. default-domain:: mongodb

Operational factors help shape data modeling decisions in MongoDB.
These factors have implications for database and application
performance as well as future maintenance and development costs.

.. _data-model-document-growth:

Document Growth
---------------

Certain updates to documents can increase the document size, such as
pushing elements to an array and adding new fields. If the document
size exceeds the allocated space for that document, MongoDB relocates
the document on disk. This internal relocation can be both time and
resource consuming. Although MongoDB automatically provides
:doc:`record padding </core/record-padding>` to minimize the occurrence
of relocation, document growth is an important consideration during
data modeling decisions.

For instance, if your documents are likely to grow significantly,
adding new fields or pushing elements to an array in a heavily
denormalized collection may be more expensive than in a normalized
collection. With a normalized collection, you might be inserting new
documents and adding references whereas with a denormalized collection,
you might be updating a large document as a whole.

Even though MongoDB adaptively adjusts the amount of padding to reduce
occurrences of relocation, in some exceptional cases, you may also need
to manually handle document growth such as with *pre-allocation*. Refer
to :ecosystem:`Pre-Aggregated Reports Use Case
</use-cases/pre-aggregated-reports>` for an example of the
*pre-allocation* approach to handling document growth.

.. _data-model-atomicity:
.. _data-modeling-atomicity:

Atomicity
---------

In MongoDB, operations are atomic at the :term:`document` level: no
single write operation can atomically affect more than one document or
more than one collection. [#record-atomicity]_ As such, fields that
need to be modified together atomically should be in the same document
whereas fields that can be modified non-atomically can be located in
separate documents.

A denormalized schema with nesting of embedded documents can facilitate
atomic write operations since all related data is stored in a single
document. By contrast, with a normalized schema that stores related
information in a number of documents, update operations can involve
many individual writes.

See :ref:`data-modeling-atomic-operation` for an example of atomic
updates within a single document.

.. [#record-atomicity] Document-level atomic operations include all
   operations within a single MongoDB document record: operations that
   affect multiple sub-documents within that single record are still
   atomic.

Sharding
--------

MongoDB uses :term:`sharding`, or horizontal scaling, to support
deployments with very large data sets and high throughput operations.
Sharding allows users to :term:`partition` a :term:`collection` within
a database to distribute the collection's documents across a number of
:program:`mongod` instances or :term:`shards <shard>`.

To distribute data among the shards for a sharded collection, MongoDB
uses the :ref:`shard key <shard-key>`. Selecting the proper :ref:`shard
key <shard-key>` has significant implications for performance, such as
providing query isolation and increased write capacity. It is important
to consider carefully the field, or fields, to use as the shard key.

See :doc:`/core/sharding-introduction` and
:doc:`/core/sharding-shard-key` for more information.

Indexes
-------

Create indexes to support common queries. Generally, indexes and index
use in MongoDB correspond to indexes and index use in relational
database. Build indexes on fields that appear often in queries and for
all operations that return sorted results. MongoDB automatically
creates a unique index on the ``_id`` field.

As you create indexes, consider the following behaviors of indexes:

- Each index requires at least 8KB of data space.

- Adding an index has some negative performance impact for write
  operations. For collections with high write-to-read ratio, indexes
  are expensive since each insert must add keys to each index.

- Collections with high proportion of read operations to write
  operations often benefit from additional indexes. Indexes do not
  affect un-indexed read operations.

See :doc:`/applications/indexes` for more information on determining
indexes. Additionally, the MongoDB :doc:`database profiler
</tutorial/manage-the-database-profiler>` may help identify
inefficient queries.

.. _data-model-large-number-of-collections:

Large Number of Collections
---------------------------

In certain situations, you might choose to store similar information in
several collections rather than in a single collection.

Consider a sample collection ``logs`` that stores log documents for
various environment and applications. The ``logs`` collection contains
documents of the following form:

.. code-block:: javascript

   { log: "dev", ts: ..., info: ... }
   { log: "debug", ts: ..., info: ...}

If the total number of documents is low, you may group documents into
collection by type. For logs, consider maintaining distinct log
collections, such as ``logs.dev`` and ``logs.debug``. The ``logs.dev``
collection would contain only the documents related to the dev
environment.

Generally, having large number of collections has no significant
performance penalty and results in very good performance. Distinct
collections are very important for high-throughput batch processing.

When using models that have a large number of collections, consider
the following behaviors:

- Each collection has a certain minimum overhead of a few kilobytes.

- Each index, including the index on ``_id``, requires at least 8KB of
  data space.

- For each :term:`database`, a single namespace file (i.e.
  ``<database>.ns``) stores all meta-data for that database, and each
  index and collection has its own entry in the namespace file. MongoDB
  places :limit:`limits on the size of namespace files 
  <Size of Namespace File>`.

- MongoDB has :limit:`limits on the number of namespaces 
  <Number of Namespaces>`. You may wish to know the current number of
  namespaces in order to determine how many additional namespaces the
  database can support. To get the current number of namespaces, run
  the following in the :program:`mongo` shell:

  .. code-block:: javascript

     db.system.namespaces.count()

  .. todo make a tutorial called "how to change size of namespace file"

  The limit on the number of namespaces depend on the ``<database>.ns``
  size. The namespace file defaults to 16 MB. 
  
  To change the size of the *new* namespace file, start the server with
  the option :option:`--nssize \<new size MB\> <--nssize>`. For
  existing databases, after starting up the server with
  :option:`--nssize`, run the :method:`db.repairDatabase()` command
  from the :program:`mongo` shell. For impacts and considerations on
  running :method:`db.repairDatabase()`, see
  :dbcommand:`repairDatabase`.

Data Lifecycle Management
-------------------------

Data modeling decisions should take data lifecycle management into
consideration.

The :doc:`Time to Live or TTL feature </tutorial/expire-data>` of
collections expires documents after a period of time. Consider using
the TTL feature if your application requires some data to persist in
the database for a limited period of time.

Additionally, if your application only uses recently inserted
documents, consider :doc:`/core/capped-collections`. Capped collections
provide *first-in-first-out* (FIFO) management of inserted documents
and efficiently support operations that insert and read documents based
on insertion order.
