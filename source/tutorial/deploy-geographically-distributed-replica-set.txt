=============================================
Deploy a Geographically Redundant Replica Set
=============================================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

This tutorial outlines the process for deploying a :term:`replica set`
with :doc:`members in multiple locations
</core/replica-set-architecture-geographically-distributed>`. The
tutorial addresses three-member sets and five-member replica sets. If
you have an even number of replica set members, add an arbiter to
deploy an odd number replica set.

For more information on distributed replica sets, see
:doc:`/core/replica-set-architecture-geographically-distributed`. See
also :doc:`/core/replica-set-architectures` and see :doc:`/replication`.

Overview
--------

While :term:`replica sets <replica set>` provide basic protection
against single-instance failure, replica sets whose members are all
located in a single facility are susceptible to errors in that
facility. Power outages, network interruptions, and natural disasters
are all issues that can affect replica sets whose members are colocated.
To protect against these classes of failures, deploy a
replica set with one or more members in a geographically distinct
facility or data center to provide redundancy.

Considerations
--------------

.. include:: /includes/fact-prod-rs-deployment-considerations.rst

Distribution of the Members
~~~~~~~~~~~~~~~~~~~~~~~~~~~

If possible, use an odd number of data centers, and choose a
distribution of members that maximizes the likelihood that even with a
loss of a data center, the remaining replica set members can form a
majority or at minimum, provide a copy of your data.

Voting Members
~~~~~~~~~~~~~~

Never deploy more than seven voting members.

Procedures
----------

.. _replica-set-deploy-distributed-three-member:

Deploy a Geographically Redundant Three-Member Replica Set
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For a geographically redundant three-member replica set deployment, you
must decide how to distribute your system. Some possible distributions
for the three members are:

- Across Three Data Centers: One members to each site.

- Across Two Data Centers: Two members to Site A and one member to Site
  B. If one of the members of the replica set is an arbiter, distribute
  the arbiter to Site A with a data-bearing member.

.. include:: /images/replica-set-three-members-geographically-distributed.rst

.. include:: /tutorial/deploy-replica-set.txt
   :start-after: begin-deployment-content
   :end-before: end-3member

6. Optional. Configure the member eligibility for becoming primary.
   In some cases, you may prefer that the members in one data center be
   elected primary before the members in the other data centers.
   
   For example, to lower the relative eligibility of the the member
   located in one of the sites (in this example, mongodb2.example.net),
   set the member's priority to 0.5.

   .. include:: /includes/fact-distributed-rs-siteB-config.rst

   After these commands return, you have a geographically redundant
   three-member replica set.

.. include:: /tutorial/deploy-replica-set.txt
   :start-after: begin-conclusion-content
   :end-before: end-conclusion-content

Deploy a Geographically Redundant Five-Member Replica Set
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For a geographically redundant five-member replica set deployment, you
must decide how to distribute your system. Some possible distributions
for the five members are:

- Across Three Data Centers: Two members in Site A, two members in Site
  B, one member in Site C.

- Across Four Data Centers: Two members in one site, and one member in
  the other three sites.

- Across Five Data Centers: One members in each site.

- Across Two Data Centers: Three members in Site A and two members in
  Site B.

To deploy a geographically redundant five-member set:
`````````````````````````````````````````````````````

The following five-member replica set includes an arbiter.

.. include:: /tutorial/deploy-replica-set.txt
   :start-after: begin-deployment-content
   :end-before: end-4member

5. Add the remaining members to the replica set using
   :method:`rs.add()` in a :binary:`~bin.mongo` shell connected to the
   current primary. The commands should resemble the following:

   .. code-block:: javascript

      rs.add("mongodb1.example.net")
      rs.add("mongodb2.example.net")
      rs.add("mongodb3.example.net")

   When complete, you should have a fully functional replica set.
   The new replica set will elect a :term:`primary`.

#. In the same shell session, issue the following command to add the
   arbiter (e.g. ``mongodb4.example.net``):

   .. code-block:: javascript

      rs.addArb("mongodb4.example.net")

#. Optional. Configure the member eligibility for becoming primary.
   In some cases, you may prefer that the members in one data center be
   elected primary before the members in the other data centers.
   
   For example, to lower the relative eligibility of the the member
   located in one of the sites (in this example, mongodb2.example.net),
   set the member's priority to 0.5.

   .. include:: /includes/fact-distributed-rs-siteB-config.rst

.. include:: /tutorial/deploy-replica-set.txt
   :start-after: begin-conclusion-content
   :end-before: end-conclusion-content

