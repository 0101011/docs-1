=============================================
Deploy a Geographically Redundant Replica Set
=============================================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

This tutorial outlines the process for deploying a :term:`replica set`
with :doc:`members in multiple locations
</core/replica-set-architecture-geographically-distributed>`. The
tutorial addresses three-member sets, four-member sets, and
considerations for deploying replica sets with more than four members.

For more information on distributed replica sets, see
:doc:`/core/replica-set-architecture-geographically-distributed`. See
also :doc:`/core/replica-set-architectures` and see :doc:`/replication`.

Overview
--------

While :term:`replica sets <replica set>` provide basic protection
against single-instance failure, replica sets whose members are all
located in a single facility are susceptible to errors in that
facility. Power outages, network interruptions, and natural disasters
are all issues that can affect replica sets whose members are colocated.
To protect against these classes of failures, deploy a
replica set with one or more members in a geographically distinct
facility or data center to provide redundancy.

Considerations
--------------

.. include:: /includes/fact-prod-rs-deployment-considerations.rst

Distribution of the Members
~~~~~~~~~~~~~~~~~~~~~~~~~~~

If possible, use an odd number of data centers, and choose a
distribution of members that maximizes the likelihood that even with a
loss of a data center, the remaining replica set members can form a
majority or at minimum, provide a copy of your data.

Procedures
----------

.. _replica-set-deploy-distributed-three-member:

Deploy a Geographically Redundant Three-Member Replica Set
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For a geographically redundant three-member replica set deployment, you
must decide how to distribute your system. Some possible distributions
for the three members are:

- Across Three Data Centers: One members to each site.

- Across Two Data Centers: Two members to Site A and one member to Site
  B. If one of the members of the replica set is an arbiter, distribute
  the arbiter to Site A with a data-bearing member.

.. include:: /images/replica-set-three-members-geographically-distributed.rst

.. include:: /tutorial/deploy-replica-set.txt
   :start-after: begin-deployment-content
   :end-before: end-3member

6. Optional. Configure the member eligibility for becoming primary.
   In some cases, you may prefer that the members in one data center be
   elected primary before the members in the other data centers.
   
   For example, to lower the relative eligibility of the the member
   located in one of the sites (in this example, mongodb2.example.net),
   set the member's priority to 0.5.

   .. include:: /includes/fact-distributed-rs-siteB-config.rst

   After these commands return, you have a geographically redundant
   three-member replica set.

.. include:: /tutorial/deploy-replica-set.txt
   :start-after: begin-conclusion-content
   :end-before: end-conclusion-content

.. _replica-set-deploy-distributed-four-member:

Deploy a Geographically Redundant Four-Member Replica Set
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

A geographically redundant four-member deployment has two additional
considerations:

- You must add an :term:`arbiter` to ensure an odd number of votes. The
  arbiter can run on a system that is also used for an application
  server or on the same machine as another MongoDB process.

- You must decide how to distribute your systems. Some possible
  distributions for the four members plus the arbiter are:

  - Across Three Data Centers: Two members in Site A, two members in
    Site B, one member in Site C.

  - Across Four Data Centers: Two members in one site, and one member
    in the other three sites.

  - Across Five Data Centers: One members in each site.

  - Across Two Data Centers: Three members in Site A and two members in
    Site B.

To deploy a geographically redundant four-member set:
`````````````````````````````````````````````````````

.. include:: /tutorial/deploy-replica-set.txt
   :start-after: begin-deployment-content
   :end-before: end-4member

5. Add the remaining members to the replica set using
   :method:`rs.add()` in a :program:`mongo` shell connected to the
   current primary. The commands should resemble the following:

   .. code-block:: javascript

      rs.add("mongodb1.example.net")
      rs.add("mongodb2.example.net")
      rs.add("mongodb3.example.net")

   When complete, you should have a fully functional replica set.
   The new replica set will elect a :term:`primary`.

#. In the same shell session, issue the following command to add the
   arbiter (e.g. ``mongodb4.example.net``):

   .. code-block:: javascript

      rs.addArb("mongodb4.example.net")

#. Optional. Configure the member eligibility for becoming primary.
   In some cases, you may prefer that the members in one data center be
   elected primary before the members in the other data centers.
   
   For example, to lower the relative eligibility of the the member
   located in one of the sites (in this example, mongodb2.example.net),
   set the member's priority to 0.5.

   .. include:: /includes/fact-distributed-rs-siteB-config.rst

.. include:: /tutorial/deploy-replica-set.txt
   :start-after: begin-conclusion-content
   :end-before: end-conclusion-content

Deploy a Geographically Redundant Set with More than Four Members
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The above procedures detail the steps necessary for deploying a
geographically redundant replica set. Larger replica set deployments
generally follow the same steps, but have additional considerations:

- Never deploy more than seven voting members.

- If you have an even number of members, similar to :ref:`the procedure
  for a four-member set <replica-set-deploy-distributed-four-member>`,
  deploy an arbiter.
